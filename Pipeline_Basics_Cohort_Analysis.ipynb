{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline Basics: Cohort Analysis",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theventurecity/analytics/blob/master/Pipeline_Basics_Cohort_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OpetXnsuOL_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![TheVentureCity](https://theventure.city/wp-content/uploads/2017/06/Theventurecity-logoweb-1.png)\n",
        "\n",
        "# Pipeline Basics: Cohort Analysis\n",
        "1. Read raw event log data from a CSV\n",
        "2. Transform that data into meaningful insights\n",
        "3. Write the transformed data to Google Sheets \n",
        "4. Visualize insights in Google Data Studio\n",
        "\n",
        "## Before you begin\n",
        "\n",
        "- This notebook is shared with read-only access. To run this notebook yourself, first click \"**Open in Playground**\" in the toolbar above. That will create a separate instance that you can run and/or save a copy of to your own Google Drive. \n",
        "\n",
        "- To run each cell, hit **Shift-Enter**, which will run the contents of the active cell and move to the next cell. This includes the markup cells (such as this one).\n",
        "\n",
        "- When you run the first block of Python code, you will get a message that says, \"**Warning: This notebook was not authored by Google.**\" Please be aware that we are **NOT** accessing your data shared with Google or reading data and credentials from other sessions. This notebook reads data from GitHub and writes to a Google Sheet that only you have access to and can control. We recommend you click the box to \"**Reset all runtimes before running**\" for extra information security."
      ]
    },
    {
      "metadata": {
        "id": "GHB2MNA2zwjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import relevant Python libraries"
      ]
    },
    {
      "metadata": {
        "id": "9-n5RAG2N9-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Pandas, Numpy, and date functions to read the data from its source\n",
        "### and manipulate it in memory\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from datetime import datetime\n",
        "import math\n",
        "\n",
        "\n",
        "### Google account authentication to give the code access to your Google account\n",
        "### and gspread to enable writing to Google Sheets\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "\n",
        "### The IPython.display library allows us to embed an iFrame within this \n",
        "### notebook\n",
        "from IPython.display import IFrame\n",
        "\n",
        "\n",
        "### To run this with functions from TheVentureCity's GitHub repository,\n",
        "### clone the repository to the Google Colaboratory runtime environment\n",
        "### and then import the code found in growth_accounting.py into a library\n",
        "### called \"ga\". This code allows us to run pre-existing functions rather than\n",
        "### having to spell them out within the notebook\n",
        "### THIS IS ONLY APPLICABLE IF YOU WANT TO ACCESS THOSE FUNCTIONS ###\n",
        "### THIS VERSION OF THE NOTEBOOK DEFINES THE FUNCTIONS INLINE     ###\n",
        "# !if [ ! -d \"analytics\" ]; then git clone https://github.com/theventurecity/analytics.git; fi\n",
        "# from importlib.machinery import SourceFileLoader\n",
        "# ga = SourceFileLoader('growth_accounting', 'analytics/python/growth_accounting.py').load_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHPavVhwwSMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Extract: read raw event log data from a CSV"
      ]
    },
    {
      "metadata": {
        "id": "jgo6Umpxw5I1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This example uses a data file for a Sample Company from our GitHub repository. In this step we read the data file into memory as a Pandas dataframe we name \"t.\""
      ]
    },
    {
      "metadata": {
        "id": "v3KNCE2Sb3-S",
        "colab_type": "code",
        "outputId": "06c597dc-bd04-4f23-a181-2bb0a2d65e9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "# Edit this filename to your local filename.csv if using a local CSV file\n",
        "filename = 'https://raw.githubusercontent.com/theventurecity/Analytics/master/data/SmileCo_transactions.csv'\n",
        "\n",
        "t = pd.read_csv(filename)\n",
        "t.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>activity_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1209696</th>\n",
              "      <td>438E84E2-CDD3-4311-BC67-8B726149CFCB</td>\n",
              "      <td>2019-02-20 02:31:37.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209697</th>\n",
              "      <td>8CC36A55-4B70-48D6-A67C-16C290D62988</td>\n",
              "      <td>2019-02-20 02:32:50.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209698</th>\n",
              "      <td>966294A9-F98E-491F-A5F2-2B07B07B6ED7</td>\n",
              "      <td>2019-02-20 02:33:11.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209699</th>\n",
              "      <td>8130537F-9317-48E5-BA62-19766B6A5032</td>\n",
              "      <td>2019-02-20 02:33:50.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209700</th>\n",
              "      <td>3AFC060B-B90A-4E5F-B3DF-0FEACA0B0252</td>\n",
              "      <td>2019-02-20 02:34:37.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209701</th>\n",
              "      <td>FFA89731-278F-48A0-8433-231E7FD7B2C4</td>\n",
              "      <td>2019-02-20 02:34:59.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209702</th>\n",
              "      <td>7983860B-8D92-4DC3-ADC8-8AACD3A110B4</td>\n",
              "      <td>2019-02-20 02:35:03.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209703</th>\n",
              "      <td>ffffffff-d707-9c07-0000-000000000000</td>\n",
              "      <td>2019-02-20 02:35:04.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209704</th>\n",
              "      <td>16A7BE74-F509-4AB8-B043-11533D8F3B5E</td>\n",
              "      <td>2019-02-20 02:36:33.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209705</th>\n",
              "      <td>16A7BE74-F509-4AB8-B043-11533D8F3B5E</td>\n",
              "      <td>2019-02-20 02:36:35.0000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      user_id                activity_date\n",
              "1209696  438E84E2-CDD3-4311-BC67-8B726149CFCB  2019-02-20 02:31:37.0000000\n",
              "1209697  8CC36A55-4B70-48D6-A67C-16C290D62988  2019-02-20 02:32:50.0000000\n",
              "1209698  966294A9-F98E-491F-A5F2-2B07B07B6ED7  2019-02-20 02:33:11.0000000\n",
              "1209699  8130537F-9317-48E5-BA62-19766B6A5032  2019-02-20 02:33:50.0000000\n",
              "1209700  3AFC060B-B90A-4E5F-B3DF-0FEACA0B0252  2019-02-20 02:34:37.0000000\n",
              "1209701  FFA89731-278F-48A0-8433-231E7FD7B2C4  2019-02-20 02:34:59.0000000\n",
              "1209702  7983860B-8D92-4DC3-ADC8-8AACD3A110B4  2019-02-20 02:35:03.0000000\n",
              "1209703  ffffffff-d707-9c07-0000-000000000000  2019-02-20 02:35:04.0000000\n",
              "1209704  16A7BE74-F509-4AB8-B043-11533D8F3B5E  2019-02-20 02:36:33.0000000\n",
              "1209705  16A7BE74-F509-4AB8-B043-11533D8F3B5E  2019-02-20 02:36:35.0000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "aTeIz9GPwYV1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Transform the raw data into meaningful insights\n",
        "### 2.1 Create Daily Active Users (DAU) dataframe\n",
        "The **DAU** dataframe aggregates all activity by user and day. "
      ]
    },
    {
      "metadata": {
        "id": "OvvX_fkKOmME",
        "colab_type": "code",
        "outputId": "9ca149b2-0d68-4f17-c274-20fa0faf9f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "# The create_dau_df function takes as inputs a dataframe of transactions and \n",
        "# the names of the three key event log columns: User ID, Activity Date, and \n",
        "# Income Amount (could be revenue or contribution margin). Next it ensures that\n",
        "# the Activity Date column is a date and the User ID is a string. Then it groups\n",
        "# all of the transaction records to calculate the sum of the Income Amount\n",
        "# by User ID and Activity Date combination\n",
        "\n",
        "def create_dau_df(transactions, \n",
        "                  user_id = 'user_id', \n",
        "                  activity_date = 'activity_date', \n",
        "                  inc_amt = 'inc_amt'):\n",
        "    \n",
        "    # Ensure correct data types\n",
        "    transactions[activity_date] = pd.to_datetime(transactions[activity_date]).dt.date\n",
        "    transactions[user_id] = transactions[user_id].astype('str')\n",
        "    \n",
        "    \n",
        "    # If there is no inc_amt available in the data set, add a column of ones\n",
        "    if inc_amt is None:\n",
        "        transactions['inc_amt'] = 1\n",
        "        inc_amt = 'inc_amt'\n",
        "        \n",
        "    \n",
        "    # Group by user_id and activity_date, calculate the sum of the inc_amt\n",
        "    # and return standardized names for each column\n",
        "    dau = (transactions\n",
        "           .groupby([user_id, activity_date], as_index = False)\n",
        "           .agg({'inc_amt' : 'sum'})\n",
        "           .rename(columns = {user_id : 'user_id', \n",
        "                              activity_date : 'activity_date', \n",
        "                              inc_amt : 'inc_amt'})\n",
        "          )\n",
        "        \n",
        "    return dau\n",
        "  \n",
        "  \n",
        "# Run the function above and show the first ten rows  \n",
        "dau = create_dau_df(t, \n",
        "                    user_id = 'user_id', \n",
        "                    activity_date = 'activity_date', \n",
        "                    inc_amt = None)\n",
        "dau.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>activity_date</th>\n",
              "      <th>inc_amt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000000-0000-d200-0000-000000000000</td>\n",
              "      <td>2018-04-12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000000-0000-d200-0000-000000000000</td>\n",
              "      <td>2018-04-14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000000-0000-d200-0000-000000000000</td>\n",
              "      <td>2018-04-15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000000-0000-d200-0000-000000000000</td>\n",
              "      <td>2018-04-16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000000-0006-a79c-0000-000000000000</td>\n",
              "      <td>2019-02-10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00000000-0006-a79c-0000-000000000000</td>\n",
              "      <td>2019-02-11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00000000-000a-f125-0000-000000000000</td>\n",
              "      <td>2018-09-11</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00000000-000c-602b-0000-000000000000</td>\n",
              "      <td>2018-09-21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00000000-000c-602b-0000-000000000000</td>\n",
              "      <td>2018-09-22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00000000-000c-602b-0000-000000000000</td>\n",
              "      <td>2018-09-23</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                user_id activity_date  inc_amt\n",
              "0  00000000-0000-d200-0000-000000000000    2018-04-12        1\n",
              "1  00000000-0000-d200-0000-000000000000    2018-04-14        1\n",
              "2  00000000-0000-d200-0000-000000000000    2018-04-15        1\n",
              "3  00000000-0000-d200-0000-000000000000    2018-04-16        1\n",
              "4  00000000-0006-a79c-0000-000000000000    2019-02-10        2\n",
              "5  00000000-0006-a79c-0000-000000000000    2019-02-11        1\n",
              "6  00000000-000a-f125-0000-000000000000    2018-09-11        3\n",
              "7  00000000-000c-602b-0000-000000000000    2018-09-21        1\n",
              "8  00000000-000c-602b-0000-000000000000    2018-09-22        1\n",
              "9  00000000-000c-602b-0000-000000000000    2018-09-23        2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "CGXjLYIjxgo5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Create a separate dataframe to hold each user's first activity date\n",
        "Calculate the **first activity date** for each user_id in the DAU dataframe, and store it in its own dataframe (**first_dt**). This step is optional because it can be executed within the **create_dau_decorated_df** function below, but we are including it here to illustrate better the mechanics of what is happening."
      ]
    },
    {
      "metadata": {
        "id": "0Rtr2KqNx5Kh",
        "colab_type": "code",
        "outputId": "6280d818-fba7-4079-e733-519f7b099482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "cell_type": "code",
      "source": [
        "# The create_first_dt_df function takes as its input the DAU dataframe created\n",
        "# above. After creating a copy of the original DAU dataframe so as not to \n",
        "# affect the original, it creates a new first_dt dataframe. Using the groupby\n",
        "# and agg functions, it finds the minimum Activity Date for each User ID. Then \n",
        "# it specifies the week ('first_week') and month ('first_month') in which the \n",
        "# first Activity Date is found. \n",
        "\n",
        "def create_first_dt_df(dau_df):\n",
        "    print('Creating first_dt dataframe')\n",
        "    \n",
        "    # Create copy of input dataframe\n",
        "    dau = dau_df.copy()\n",
        "    \n",
        "    # Use groupby to find the minimum activity_date for each user_id\n",
        "    first_dt = (dau.groupby(['user_id'], as_index = False)\n",
        "                .agg({'activity_date' : 'min'})\n",
        "                .rename(columns = { 'activity_date' : 'first_dt' })\n",
        "               )\n",
        "    \n",
        "    # Ensure that the first_dt field is a date\n",
        "    first_dt['first_dt'] = pd.to_datetime(first_dt['first_dt']).dt.date\n",
        "    \n",
        "    # Add two new columns with the first_week and first_month of the first_dt\n",
        "    first_dt['first_week'] = pd.to_datetime(first_dt['first_dt']).dt.to_period('W')\n",
        "    first_dt['first_month'] = pd.to_datetime(first_dt['first_dt']).dt.to_period('M')\n",
        "    \n",
        "    return first_dt\n",
        "  \n",
        "  \n",
        "# Run the function above and show the first ten rows  \n",
        "first_dt = create_first_dt_df(dau)\n",
        "first_dt.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating first_dt dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>first_dt</th>\n",
              "      <th>first_week</th>\n",
              "      <th>first_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000000-0000-d200-0000-000000000000</td>\n",
              "      <td>2018-04-12</td>\n",
              "      <td>2018-04-09/2018-04-15</td>\n",
              "      <td>2018-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00000000-0006-a79c-0000-000000000000</td>\n",
              "      <td>2019-02-10</td>\n",
              "      <td>2019-02-04/2019-02-10</td>\n",
              "      <td>2019-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00000000-000a-f125-0000-000000000000</td>\n",
              "      <td>2018-09-11</td>\n",
              "      <td>2018-09-10/2018-09-16</td>\n",
              "      <td>2018-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00000000-000c-602b-0000-000000000000</td>\n",
              "      <td>2018-09-21</td>\n",
              "      <td>2018-09-17/2018-09-23</td>\n",
              "      <td>2018-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00000000-000c-7de8-0000-000000000000</td>\n",
              "      <td>2018-06-29</td>\n",
              "      <td>2018-06-25/2018-07-01</td>\n",
              "      <td>2018-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00000000-000f-6f9b-0000-000000000000</td>\n",
              "      <td>2018-11-13</td>\n",
              "      <td>2018-11-12/2018-11-18</td>\n",
              "      <td>2018-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>00000000-001c-d249-0000-000000000000</td>\n",
              "      <td>2018-10-22</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00000000-001f-fedd-0000-000000000000</td>\n",
              "      <td>2018-10-22</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00000000-0034-d414-0000-000000000000</td>\n",
              "      <td>2018-10-21</td>\n",
              "      <td>2018-10-15/2018-10-21</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00000000-0039-d2f3-0000-000000000000</td>\n",
              "      <td>2018-04-26</td>\n",
              "      <td>2018-04-23/2018-04-29</td>\n",
              "      <td>2018-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                user_id    first_dt            first_week  \\\n",
              "0  00000000-0000-d200-0000-000000000000  2018-04-12 2018-04-09/2018-04-15   \n",
              "1  00000000-0006-a79c-0000-000000000000  2019-02-10 2019-02-04/2019-02-10   \n",
              "2  00000000-000a-f125-0000-000000000000  2018-09-11 2018-09-10/2018-09-16   \n",
              "3  00000000-000c-602b-0000-000000000000  2018-09-21 2018-09-17/2018-09-23   \n",
              "4  00000000-000c-7de8-0000-000000000000  2018-06-29 2018-06-25/2018-07-01   \n",
              "5  00000000-000f-6f9b-0000-000000000000  2018-11-13 2018-11-12/2018-11-18   \n",
              "6  00000000-001c-d249-0000-000000000000  2018-10-22 2018-10-22/2018-10-28   \n",
              "7  00000000-001f-fedd-0000-000000000000  2018-10-22 2018-10-22/2018-10-28   \n",
              "8  00000000-0034-d414-0000-000000000000  2018-10-21 2018-10-15/2018-10-21   \n",
              "9  00000000-0039-d2f3-0000-000000000000  2018-04-26 2018-04-23/2018-04-29   \n",
              "\n",
              "  first_month  \n",
              "0     2018-04  \n",
              "1     2019-02  \n",
              "2     2018-09  \n",
              "3     2018-09  \n",
              "4     2018-06  \n",
              "5     2018-11  \n",
              "6     2018-10  \n",
              "7     2018-10  \n",
              "8     2018-10  \n",
              "9     2018-04  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "sl1ofjoCzdgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3 Join DAU with First Date\n",
        "Merge the **dau** dataframe with the **first_dt** dataframe and call it \"**DAU Decorated**.\""
      ]
    },
    {
      "metadata": {
        "id": "RRRg0W1V0BgI",
        "colab_type": "code",
        "outputId": "a0447f4f-777e-49b7-b712-30611349ab88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "cell_type": "code",
      "source": [
        "# The create_dau_decorated_df takes the two data frames created above, DAU and\n",
        "# first_dt, and merges them together based on user_id. This results in a DAU\n",
        "# dataframe \"decorated\" with information about the user's first activity date,\n",
        "# first week, and first month, as shown below. Note: it is not necessary to \n",
        "# pass in the first_dt dataframe. If none is provided, the function will run\n",
        "# create_first_dt_df so it has something to merge to the DAU dataframe.\n",
        "\n",
        "def create_dau_decorated_df(dau_df, first_dt_df = None):\n",
        "    print('Creating DAU Decorated dataframe')\n",
        "    \n",
        "    # If no first_dt_df is provided, create it\n",
        "    if first_dt_df is None:\n",
        "        first_dt_df = create_first_dt_df(dau_df)\n",
        "        \n",
        "    # Do a left merge of first_dt_df into dau_df on User ID\n",
        "    dau_decorated_df = dau_df.merge(first_dt_df, how = 'left', on = 'user_id')\n",
        "\n",
        "    return dau_decorated_df\n",
        "  \n",
        "  \n",
        "# Run the function above and show the first ten rows  \n",
        "dau_decorated = create_dau_decorated_df(dau, first_dt_df = first_dt)\n",
        "dau_decorated.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating DAU Decorated dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>activity_date</th>\n",
              "      <th>inc_amt</th>\n",
              "      <th>first_dt</th>\n",
              "      <th>first_week</th>\n",
              "      <th>first_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>502520</th>\n",
              "      <td>ffffffff-fff7-aa1b-0000-000000000000</td>\n",
              "      <td>2018-10-29</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502521</th>\n",
              "      <td>ffffffff-fff7-aa1b-0000-000000000000</td>\n",
              "      <td>2018-11-04</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502522</th>\n",
              "      <td>ffffffff-fff7-aa1b-0000-000000000000</td>\n",
              "      <td>2018-11-06</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502523</th>\n",
              "      <td>ffffffff-fff7-aa1b-0000-000000000000</td>\n",
              "      <td>2018-11-08</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502524</th>\n",
              "      <td>ffffffff-fff7-aa1b-0000-000000000000</td>\n",
              "      <td>2018-11-25</td>\n",
              "      <td>3</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502525</th>\n",
              "      <td>ffffffff-fff7-ce07-0000-000000000000</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>2018-11-26/2018-12-02</td>\n",
              "      <td>2018-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502526</th>\n",
              "      <td>ffffffff-fff8-9004-0000-000000000000</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502527</th>\n",
              "      <td>ffffffff-fff9-4654-0000-000000000000</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>4</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502528</th>\n",
              "      <td>ffffffff-fff9-4654-0000-000000000000</td>\n",
              "      <td>2018-10-30</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-10-23</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502529</th>\n",
              "      <td>ffffffff-fffa-9b37-0000-000000000000</td>\n",
              "      <td>2018-10-27</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-10-27</td>\n",
              "      <td>2018-10-22/2018-10-28</td>\n",
              "      <td>2018-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     user_id activity_date  inc_amt  \\\n",
              "502520  ffffffff-fff7-aa1b-0000-000000000000    2018-10-29        2   \n",
              "502521  ffffffff-fff7-aa1b-0000-000000000000    2018-11-04        2   \n",
              "502522  ffffffff-fff7-aa1b-0000-000000000000    2018-11-06        2   \n",
              "502523  ffffffff-fff7-aa1b-0000-000000000000    2018-11-08        2   \n",
              "502524  ffffffff-fff7-aa1b-0000-000000000000    2018-11-25        3   \n",
              "502525  ffffffff-fff7-ce07-0000-000000000000    2018-12-01        1   \n",
              "502526  ffffffff-fff8-9004-0000-000000000000    2018-10-23        1   \n",
              "502527  ffffffff-fff9-4654-0000-000000000000    2018-10-23        4   \n",
              "502528  ffffffff-fff9-4654-0000-000000000000    2018-10-30        1   \n",
              "502529  ffffffff-fffa-9b37-0000-000000000000    2018-10-27        2   \n",
              "\n",
              "          first_dt            first_week first_month  \n",
              "502520  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502521  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502522  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502523  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502524  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502525  2018-12-01 2018-11-26/2018-12-02     2018-12  \n",
              "502526  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502527  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502528  2018-10-23 2018-10-22/2018-10-28     2018-10  \n",
              "502529  2018-10-27 2018-10-22/2018-10-28     2018-10  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "JyYfAz4RxU6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Combining the basic DAU data with the first date, week, and month for each user, **the DAU Decorated dataframe is our basic building block for many different analyses**. It allows us to use user-level data to inspect engagement, retention, and growth accounting."
      ]
    },
    {
      "metadata": {
        "id": "E9sHP5yDwAwH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.4 Calculate cohort analysis metrics\n",
        "Now that we have the \"DAU Decorated\" data frame, we can use it to calculate cohort retention and LTV metrics since they are super-important for an early-stage startup. The **create_xau_decorated_df** function below creates a monthly roll-up of the DAU Decorated data we call MAU Decorated."
      ]
    },
    {
      "metadata": {
        "id": "lZ2gzkY70psc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# For discrete time period calculations, this helper function sets the variable \n",
        "# names in the different dataframes \n",
        "def get_time_period_dict(time_period):\n",
        "    \n",
        "    time_fields_dict = {\n",
        "                        'week' : {'grouping_col' : 'Week',\n",
        "                                  'first_period_col' : 'first_week',\n",
        "                                  'frequency' : 'Weekly',\n",
        "                                  'unit' : 'Week',\n",
        "                                  'period_abbr' : 'W',\n",
        "                                  'python_period' : 'weeks'\n",
        "                                  },\n",
        "                        'month' : {'grouping_col' : 'Month_Year',\n",
        "                                   'first_period_col' : 'first_month',\n",
        "                                   'frequency' : 'Monthly',\n",
        "                                   'unit' : 'Month',\n",
        "                                   'period_abbr' : 'M',\n",
        "                                   'python_period' : 'months'\n",
        "                                  }\n",
        "                        }\n",
        "                    \n",
        "    if time_period in time_fields_dict:\n",
        "        time_fields = time_fields_dict[time_period]\n",
        "    else:\n",
        "        time_fields = None\n",
        "    \n",
        "    return time_fields\n",
        "  \n",
        "  \n",
        "  \n",
        "def increment_period(xau_grouping_col, time_period):\n",
        "    time_fields = get_time_period_dict(time_period)\n",
        "    period_abbr = time_fields['period_abbr']\n",
        "    \n",
        "    if time_period == 'week':\n",
        "        start_of_next_period = (pd.to_datetime(pd.PeriodIndex(xau_grouping_col)\n",
        "                                               .start_time \n",
        "                                               + timedelta(weeks = 1)))\n",
        "    elif time_period == 'month':\n",
        "        start_of_next_period = (pd.to_datetime(pd.PeriodIndex(xau_grouping_col, \n",
        "                                                              freq = period_abbr)\n",
        "                                               .start_time) \n",
        "                                + pd.DateOffset(months = 1))\n",
        "    else:\n",
        "        start_of_next_period = None\n",
        "        \n",
        "    if start_of_next_period is not None:\n",
        "        next_period = pd.Series(start_of_next_period).dt.to_period(period_abbr)\n",
        "    else:\n",
        "        next_period = None\n",
        "    \n",
        "    return next_period\n",
        "  \n",
        "  \n",
        "\n",
        "def create_xau_decorated_df(dau_decorated_df, time_period):\n",
        "    \n",
        "    time_fields = get_time_period_dict(time_period)\n",
        "    grouping_col = time_fields['grouping_col']\n",
        "    frequency = time_fields['frequency']\n",
        "    first_period_col = time_fields['first_period_col']\n",
        "    period_abbr = time_fields['period_abbr']\n",
        "    \n",
        "    print('Creating ' + frequency + ' Active Users Decorated dataframe')\n",
        "    \n",
        "    groupby_cols = [grouping_col, 'user_id', first_period_col]\n",
        "            \n",
        "    dau_decorated = dau_decorated_df.copy()\n",
        "    dau_decorated[grouping_col] = pd.to_datetime(dau_decorated['activity_date']).dt.to_period(period_abbr)\n",
        "    xau = (dau_decorated.groupby(groupby_cols, as_index = False)['inc_amt'].sum())\n",
        "    xau['Next_' + grouping_col] = increment_period(xau[grouping_col], time_period)\n",
        "    \n",
        "    output_cols = [grouping_col, 'user_id', 'inc_amt', first_period_col, 'Next_' + grouping_col]\n",
        "    xau = xau[output_cols]\n",
        "    \n",
        "    return xau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWQ_Ppq_0uwj",
        "colab_type": "code",
        "outputId": "d5844a15-854b-4214-f6bf-4f29352396c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "cell_type": "code",
      "source": [
        "mau_decorated = create_xau_decorated_df(dau_decorated, 'month')\n",
        "mau_decorated.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Monthly Active Users Decorated dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month_Year</th>\n",
              "      <th>user_id</th>\n",
              "      <th>inc_amt</th>\n",
              "      <th>first_month</th>\n",
              "      <th>Next_Month_Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56827</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-fe29-7514-0000-000000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56828</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-fe56-e310-0000-000000000000</td>\n",
              "      <td>6</td>\n",
              "      <td>2019-02</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56829</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-fe8d-63e7-0000-000000000000</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-02</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56830</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-fec5-8375-0000-000000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56831</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-fed5-7da3-0000-000000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56832</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-fef6-d125-0000-000000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56833</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-ff40-bd27-0000-000000000000</td>\n",
              "      <td>6</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56834</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-ff54-afcb-0000-000000000000</td>\n",
              "      <td>5</td>\n",
              "      <td>2018-10</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56835</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-ff5b-02fb-0000-000000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-01</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56836</th>\n",
              "      <td>2019-02</td>\n",
              "      <td>ffffffff-ff61-98d3-0000-000000000000</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-02</td>\n",
              "      <td>2019-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Month_Year                               user_id  inc_amt first_month  \\\n",
              "56827    2019-02  ffffffff-fe29-7514-0000-000000000000        1     2019-01   \n",
              "56828    2019-02  ffffffff-fe56-e310-0000-000000000000        6     2019-02   \n",
              "56829    2019-02  ffffffff-fe8d-63e7-0000-000000000000        2     2019-02   \n",
              "56830    2019-02  ffffffff-fec5-8375-0000-000000000000        1     2018-10   \n",
              "56831    2019-02  ffffffff-fed5-7da3-0000-000000000000        1     2018-10   \n",
              "56832    2019-02  ffffffff-fef6-d125-0000-000000000000        1     2018-10   \n",
              "56833    2019-02  ffffffff-ff40-bd27-0000-000000000000        6     2018-10   \n",
              "56834    2019-02  ffffffff-ff54-afcb-0000-000000000000        5     2018-10   \n",
              "56835    2019-02  ffffffff-ff5b-02fb-0000-000000000000        1     2019-01   \n",
              "56836    2019-02  ffffffff-ff61-98d3-0000-000000000000        1     2019-02   \n",
              "\n",
              "      Next_Month_Year  \n",
              "56827         2019-03  \n",
              "56828         2019-03  \n",
              "56829         2019-03  \n",
              "56830         2019-03  \n",
              "56831         2019-03  \n",
              "56832         2019-03  \n",
              "56833         2019-03  \n",
              "56834         2019-03  \n",
              "56835         2019-03  \n",
              "56836         2019-03  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "q-hrJq9G27GZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The **xau_retention_by_cohort_df** function below helps us calculate what happens to the cohort of users that comes in as a new customer each month. It looks at how many of them continue to use the product (expressed as a number and as a percentage), how much income they generate each month, the income per customer, and the cumulative income per customer. This information leads to several insightful visuals as we will see below."
      ]
    },
    {
      "metadata": {
        "id": "ewa5yayk3Cg4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Calculate the user retention by cohort defined by any weekly or monthly time period\n",
        "def xau_retention_by_cohort_df(xau_decorated_df, \n",
        "                               time_period, \n",
        "                               recent_periods_back_to_exclude = 1, \n",
        "                               date_limit = None):\n",
        "    \n",
        "    time_fields = get_time_period_dict(time_period)\n",
        "    grouping_col = time_fields['grouping_col']\n",
        "    first_period_col = time_fields['first_period_col']\n",
        "    unit = time_fields['unit']\n",
        "    period_abbr = time_fields['period_abbr']\n",
        "        \n",
        "    since_col = '%ss Since First' % unit\n",
        "    \n",
        "    if date_limit is not None:\n",
        "        xau_d = (xau_decorated_df[pd.PeriodIndex(xau_decorated_df[grouping_col], \n",
        "                                                 freq = period_abbr)\n",
        "                                  .start_time <= date_limit].copy())\n",
        "    else:\n",
        "        xau_d = xau_decorated_df.copy()\n",
        "    \n",
        "    xau_d[since_col] = xau_d[grouping_col] - xau_d[first_period_col]\n",
        "    \n",
        "    first_groupby_cols = [first_period_col, grouping_col, since_col]\n",
        "    \n",
        "    xau_d = (xau_d.groupby(first_groupby_cols)\n",
        "             .agg({'inc_amt' : 'sum', 'user_id' : 'nunique'})\n",
        "             .rename(columns = { 'user_id' : 'cust_ct' })\n",
        "            )\n",
        "                    \n",
        "    second_groupby_cols = [first_period_col]\n",
        "    \n",
        "    xau_d['cohort_cust_ct'] = (xau_d.groupby(second_groupby_cols)['cust_ct']\n",
        "                               .transform('first'))\n",
        "    xau_d['cum_inc_amt'] = (xau_d.groupby(second_groupby_cols)['inc_amt']\n",
        "                            .cumsum())\n",
        "    \n",
        "    xau_d['cum_inc_per_cohort_cust'] = xau_d['cum_inc_amt'] / xau_d['cohort_cust_ct']\n",
        "    xau_d['cust_ret_pct'] = xau_d['cust_ct'] / xau_d['cohort_cust_ct']\n",
        "    \n",
        "    xau_d = xau_d.reset_index()\n",
        "    \n",
        "    if time_period == 'month':\n",
        "        td = pd.DateOffset(months = recent_periods_back_to_exclude)\n",
        "    elif time_period == 'week':\n",
        "        td = timedelta(weeks = recent_periods_back_to_exclude)\n",
        "    \n",
        "    last_period = pd.to_datetime(datetime.today() - td).to_period(period_abbr)\n",
        "    xau_d = xau_d.loc[xau_d[grouping_col] <= last_period]\n",
        "    \n",
        "    xau_d[first_period_col] = (pd.PeriodIndex(xau_d[first_period_col], \n",
        "                                              freq = period_abbr).start_time )\n",
        "    xau_d[grouping_col] = (pd.PeriodIndex(xau_d[grouping_col], \n",
        "                                          freq = period_abbr).start_time )\n",
        "    \n",
        "    \n",
        "       \n",
        "    return xau_d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0JEY516g3yHw",
        "colab_type": "code",
        "outputId": "f973900d-f85a-455c-cfb5-b66f2934a0be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "cell_type": "code",
      "source": [
        "mau_retention_by_cohort = xau_retention_by_cohort_df(mau_decorated, 'month')\n",
        "mau_retention_by_cohort.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_month</th>\n",
              "      <th>Month_Year</th>\n",
              "      <th>Months Since First</th>\n",
              "      <th>inc_amt</th>\n",
              "      <th>cust_ct</th>\n",
              "      <th>cohort_cust_ct</th>\n",
              "      <th>cum_inc_amt</th>\n",
              "      <th>cum_inc_per_cohort_cust</th>\n",
              "      <th>cust_ret_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>0</td>\n",
              "      <td>11029</td>\n",
              "      <td>985</td>\n",
              "      <td>985</td>\n",
              "      <td>11029</td>\n",
              "      <td>11.196954</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>1</td>\n",
              "      <td>4968</td>\n",
              "      <td>251</td>\n",
              "      <td>985</td>\n",
              "      <td>15997</td>\n",
              "      <td>16.240609</td>\n",
              "      <td>0.254822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>2301</td>\n",
              "      <td>139</td>\n",
              "      <td>985</td>\n",
              "      <td>18298</td>\n",
              "      <td>18.576650</td>\n",
              "      <td>0.141117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2018-11-01</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>3</td>\n",
              "      <td>1036</td>\n",
              "      <td>85</td>\n",
              "      <td>985</td>\n",
              "      <td>19334</td>\n",
              "      <td>19.628426</td>\n",
              "      <td>0.086294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>0</td>\n",
              "      <td>10374</td>\n",
              "      <td>672</td>\n",
              "      <td>672</td>\n",
              "      <td>10374</td>\n",
              "      <td>15.437500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>2751</td>\n",
              "      <td>166</td>\n",
              "      <td>672</td>\n",
              "      <td>13125</td>\n",
              "      <td>19.531250</td>\n",
              "      <td>0.247024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>2018-12-01</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>2</td>\n",
              "      <td>1039</td>\n",
              "      <td>86</td>\n",
              "      <td>672</td>\n",
              "      <td>14164</td>\n",
              "      <td>21.077381</td>\n",
              "      <td>0.127976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>11646</td>\n",
              "      <td>881</td>\n",
              "      <td>881</td>\n",
              "      <td>11646</td>\n",
              "      <td>13.219069</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>1</td>\n",
              "      <td>4128</td>\n",
              "      <td>247</td>\n",
              "      <td>881</td>\n",
              "      <td>15774</td>\n",
              "      <td>17.904654</td>\n",
              "      <td>0.280363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>0</td>\n",
              "      <td>2565</td>\n",
              "      <td>437</td>\n",
              "      <td>437</td>\n",
              "      <td>2565</td>\n",
              "      <td>5.869565</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    first_month Month_Year  Months Since First  inc_amt  cust_ct  \\\n",
              "95   2018-11-01 2018-11-01                   0    11029      985   \n",
              "96   2018-11-01 2018-12-01                   1     4968      251   \n",
              "97   2018-11-01 2019-01-01                   2     2301      139   \n",
              "98   2018-11-01 2019-02-01                   3     1036       85   \n",
              "99   2018-12-01 2018-12-01                   0    10374      672   \n",
              "100  2018-12-01 2019-01-01                   1     2751      166   \n",
              "101  2018-12-01 2019-02-01                   2     1039       86   \n",
              "102  2019-01-01 2019-01-01                   0    11646      881   \n",
              "103  2019-01-01 2019-02-01                   1     4128      247   \n",
              "104  2019-02-01 2019-02-01                   0     2565      437   \n",
              "\n",
              "     cohort_cust_ct  cum_inc_amt  cum_inc_per_cohort_cust  cust_ret_pct  \n",
              "95              985        11029                11.196954      1.000000  \n",
              "96              985        15997                16.240609      0.254822  \n",
              "97              985        18298                18.576650      0.141117  \n",
              "98              985        19334                19.628426      0.086294  \n",
              "99              672        10374                15.437500      1.000000  \n",
              "100             672        13125                19.531250      0.247024  \n",
              "101             672        14164                21.077381      0.127976  \n",
              "102             881        11646                13.219069      1.000000  \n",
              "103             881        15774                17.904654      0.280363  \n",
              "104             437         2565                 5.869565      1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "hzG-fUwkyM9K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Load: write the transformed data to Google Sheets \n",
        "### Establish connection to Google Sheets for writing output files\n",
        "The first time you run this cell, or after some time of inactivity, you will be asked to click on a link. That link will take you to a new tab that will authorize this script to write to Google Sheets spreadsheets in your Google Account. To enable this feature, copy the code you get into the box below and hit Enter."
      ]
    },
    {
      "metadata": {
        "id": "6XdHduQeyNSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKW2TNyWyf-1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to facilitate writing from Pandas to Google Sheets\n",
        "For use further down in this notebook."
      ]
    },
    {
      "metadata": {
        "id": "cKXbV7w0ygK4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def write_to_google_sheet(dataframe, spreadsheet_key, worksheet_name, goog_creds = gc):\n",
        "  \n",
        "  sh = goog_creds.open_by_key(spreadsheet_key)\n",
        "  \n",
        "  ws = None\n",
        "  worksheet_list = sh.worksheets()\n",
        "  for worksheet in worksheet_list:\n",
        "    if worksheet.title == worksheet_name:\n",
        "      ws = worksheet\n",
        "  if ws is None:\n",
        "    ws = sh.add_worksheet(title = worksheet_name, rows=\"1\", cols = \"1\")\n",
        "    \n",
        "  set_with_dataframe(ws, dataframe, row=1, col=1, include_index=False, \n",
        "                     include_column_header=True, resize=True, allow_formulas=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "by-pAUIe3St7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create Google Sheet for writing output files if one is not already established\n",
        "\n",
        "***Warning: you must choose from Options A and B below***.\n",
        "\n",
        "**Option A**: If you already have a Google Sheet where you store transformed data for analytics, go to that sheet, copy the long ID string from the sheet's URL in a browser, and paste it between the quotes below. Then uncomment the code and run the cell. Do NOT run the code for Option B without commenting it out.\n",
        "\n",
        "This option is especially important if you have previously linked a reporting dashboard to this Google Sheet and would like to use this ETL process to update that dashboard."
      ]
    },
    {
      "metadata": {
        "id": "GwwRwkfizC7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Option A Code\n",
        "GOOGLE_SHEET_KEY = '1-XnO_eWkRwX-E1fiA2Jkbe3kJvoyoPFsdeW7vnF6zS0' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNR7YkOY6jQX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Option B**: If you are running this for the first time and do not already have a Google Sheet where you store transformed data for analytics, uncomment and run the cell below to set the GOOGLE_SHEET_KEY variable, which will be used later in the process. Be sure to replace the \"Sample Company Analytics\" filename with one of your own."
      ]
    },
    {
      "metadata": {
        "id": "zSzoG5Bn3h8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Option B Code\n",
        "# GOOGLE_SHEET_KEY = gc.create('Sample Company Analytics').id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CUX6Br7s7ibA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After executing the cell above, a new spreadsheet with the name you supply will be shown in your sheets list on [sheets.google.com](http://sheets.google.com/). To go directly to the newly created Google Sheet, run the code block below and visit the link that it outputs. You can keep this Sheet open in a separate tab to see the data get updated whenever **write_to_google_sheet** (defined above) is called."
      ]
    },
    {
      "metadata": {
        "id": "6nn3Co-B9osp",
        "colab_type": "code",
        "outputId": "0a3967b3-51f5-4f16-ca99-677290456c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print('https://docs.google.com/spreadsheets/d/' + GOOGLE_SHEET_KEY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://docs.google.com/spreadsheets/d/1-XnO_eWkRwX-E1fiA2Jkbe3kJvoyoPFsdeW7vnF6zS0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YTuA7GJxi8P5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "write_to_google_sheet(mau_retention_by_cohort, GOOGLE_SHEET_KEY, 'MAU Retention by Cohort')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XgoZiaUa8Txs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Visualize insights in Google Data Studio\n",
        "A Google DataStudio dashboard preconfigured to read from the Google Sheet created above to visualize the data is [available at this link](https://datastudio.google.com/open/1xjS__Q6ZUXuUUARkgRvY4spYUw1ePksV) or by clicking on the Google DataStudio logo at the bottom of the chart embedded below. It is available in read-only mode for you to copy, link to your own Google Sheet tabs, and see your own data visualized."
      ]
    },
    {
      "metadata": {
        "id": "Jtw28m7Dlwo-",
        "colab_type": "code",
        "outputId": "2b24814b-9a42-4e3b-e4b6-ab906db02e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "cell_type": "code",
      "source": [
        "IFrame('https://datastudio.google.com/embed/reporting/1xjS__Q6ZUXuUUARkgRvY4spYUw1ePksV/page/EOyj', \n",
        "       width=600, \n",
        "       height=450)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"450\"\n",
              "            src=\"https://datastudio.google.com/embed/reporting/1xjS__Q6ZUXuUUARkgRvY4spYUw1ePksV/page/EOyj\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f7d1f24bef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "MEczC7003zvl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}