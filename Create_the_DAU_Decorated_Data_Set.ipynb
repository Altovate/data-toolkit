{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create the DAU Decorated Data Set",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theventurecity/data-toolkit/blob/master/Create_the_DAU_Decorated_Data_Set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OpetXnsuOL_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![TheVentureCity](https://theventure.city/wp-content/uploads/2017/06/Theventurecity-logoweb-1.png)\n",
        "\n",
        "# Create the \"DAU Decorated\" Data Set\n",
        "1. Extract raw event log data from a CSV\n",
        "2. Transform that data into the \"DAU Decorated\" dataframe\n",
        "\n",
        "## Before you begin\n",
        "\n",
        "- This notebook is shared with read-only access. To run this notebook yourself, first click \"**Open in Playground**\" in the toolbar above. That will create a separate instance that you can run and/or save a copy of to your own Google Drive. \n",
        "\n",
        "- To run each cell, hit **Shift-Enter**, which will run the contents of the active cell and move to the next cell. This includes the markup cells (such as this one).\n",
        "\n",
        "- When you run the first block of Python code, you will get a message that says, \"**Warning: This notebook was not authored by Google.**\" Please be aware that we are **NOT** accessing your data shared with Google or reading data and credentials from other sessions. This notebook reads data from GitHub and writes to a Google Sheet that only you have access to and can control. We recommend you click the box to \"**Reset all runtimes before running**\" for extra information security."
      ]
    },
    {
      "metadata": {
        "id": "GHB2MNA2zwjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import relevant Python libraries"
      ]
    },
    {
      "metadata": {
        "id": "9-n5RAG2N9-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Load the Pandas library\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHPavVhwwSMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Extract raw event log data from a CSV"
      ]
    },
    {
      "metadata": {
        "id": "jgo6Umpxw5I1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This example uses a data file for a sample company from our GitHub repository called ServBiz. In this step we read the data file into memory as a Pandas dataframe we name \"t.\""
      ]
    },
    {
      "metadata": {
        "id": "v3KNCE2Sb3-S",
        "colab_type": "code",
        "outputId": "5fe29d7e-3cf7-442c-fc62-8aacd6ba620f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# Edit this filename to your local filename.csv if using a local CSV file\n",
        "filename = 'https://raw.githubusercontent.com/theventurecity/Analytics/master/data/ServBiz_transactions.csv'\n",
        "\n",
        "t = pd.read_csv(filename)\n",
        "t.tail(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>client_id</th>\n",
              "      <th>date</th>\n",
              "      <th>value_usd</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>420781</th>\n",
              "      <td>27902A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>8.75</td>\n",
              "      <td>Enterprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420782</th>\n",
              "      <td>34181A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>18.97</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420783</th>\n",
              "      <td>30168A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>17.73</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420784</th>\n",
              "      <td>30844A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>19.98</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420785</th>\n",
              "      <td>35815A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>17.98</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420786</th>\n",
              "      <td>16958A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>17.45</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420787</th>\n",
              "      <td>13090A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>13.48</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420788</th>\n",
              "      <td>19162A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>13.64</td>\n",
              "      <td>Enterprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420789</th>\n",
              "      <td>28409A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>14.72</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420790</th>\n",
              "      <td>12080A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>18.32</td>\n",
              "      <td>SMB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       client_id        date  value_usd     segment\n",
              "420781    27902A  2019-02-28       8.75  Enterprise\n",
              "420782    34181A  2019-02-28      18.97         SMB\n",
              "420783    30168A  2019-02-28      17.73         SMB\n",
              "420784    30844A  2019-02-28      19.98         SMB\n",
              "420785    35815A  2019-02-28      17.98         SMB\n",
              "420786    16958A  2019-02-28      17.45         SMB\n",
              "420787    13090A  2019-02-28      13.48         SMB\n",
              "420788    19162A  2019-02-28      13.64  Enterprise\n",
              "420789    28409A  2019-02-28      14.72         SMB\n",
              "420790    12080A  2019-02-28      18.32         SMB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "aTeIz9GPwYV1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Transform the raw data into a cohort analysis dataframe\n",
        "### 2.1 Create Daily Active Users (DAU) dataframe\n",
        "The **DAU** dataframe aggregates all activity by user and day. By taking this approach, if any of a user's events fall within the 24 hours of a day, the user is considered active for that day. \n",
        "\n",
        "Some notes:\n",
        "\n",
        "- One of the most important aspects of this function is **standardizing the column names**. As this is the starting point, all subsequent transformation functions expect columns to be called **user_id**, **activity_date**, **inc_amt**, and **segment** (if applicable). At the point you call this function is when you map the original column names to the new ones. \n",
        "- The **inc_amt** means different things in different situations. As the name implies, it can and often does mean \"income,\" in the form of either revenue, gross margin, contribution margin, or some other monetary amount that is measurable at the transaction level. But it can refer to any number you want to count. That could mean shares, likes, page views, event counts, or anything else worthy of counting. If you specify this field as None when you run the function--which you might do if all you have is a list of dates and user_ids--then it creates a column of 1's so it can count the number of events for each user/day.\n",
        "- If you have a **segment** column in the original input data set, there is no reason not to include it here. Subsequent transformation functions contain options for including or excluding the segment column."
      ]
    },
    {
      "metadata": {
        "id": "OvvX_fkKOmME",
        "colab_type": "code",
        "outputId": "93cd86f6-384e-41e9-ca11-aaee19a49b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "# The create_dau_df function takes as inputs a dataframe of transactions and \n",
        "# the names of the three key event log columns: User ID, Activity Date, and \n",
        "# Income Amount (could be revenue or contribution margin). It can handle a \n",
        "# fourth event log column that designates a segment. Next it ensures that\n",
        "# the Activity Date column is a date and the User ID is a string. Then it groups\n",
        "# all of the transaction records to calculate the sum of the Income Amount\n",
        "# by User ID and Activity Date (and Segment, if chosen) combination\n",
        "\n",
        "def create_dau_df(transactions, \n",
        "                  user_id = 'user_id', \n",
        "                  activity_date = 'activity_date', \n",
        "                  inc_amt = 'inc_amt', \n",
        "                  segment_col = None,\n",
        "                  include_zero_inc = False):\n",
        "    \n",
        "    # Ensure correct data types\n",
        "    # If the activity_date is in date-time format, it gets rolled up into the\n",
        "    # day on which that event occurred. \n",
        "    transactions[activity_date] = pd.to_datetime(transactions[activity_date]).dt.date\n",
        "    transactions[user_id] = transactions[user_id].astype('str')\n",
        "    \n",
        "    # If there is no inc_amt available in the data set, add a column of ones\n",
        "    # Set the value of the inc_amt variable to 'inc_amt'\n",
        "    if inc_amt is None:\n",
        "        transactions['inc_amt'] = 1\n",
        "        inc_amt = 'inc_amt'\n",
        "    \n",
        "    # By default, this function only allows transactions where the inc_amt > 0\n",
        "    # This means it excludes things with negative amounts, like returns, for\n",
        "    # example. The include_zero_inc allows us to include those transactions\n",
        "    # if we see fit\n",
        "    if include_zero_inc:\n",
        "        trans_df = transactions\n",
        "    else:\n",
        "        trans_df = transactions.loc[transactions[inc_amt] > 0]\n",
        "        \n",
        "    # By default we group by user_id and activity_date. If a segment column is\n",
        "    # specified when the function is called, we include that column's name in\n",
        "    # the groupby as well. We also make sure that the segment is a string type\n",
        "    groupby_cols = [user_id, activity_date]\n",
        "    if segment_col is not None:\n",
        "        groupby_cols += [segment_col]\n",
        "        transactions[segment_col] = transactions[segment_col].astype('str')\n",
        "    \n",
        "    \n",
        "    # Group by user_id and activity_date, calculate the sum of the inc_amt\n",
        "    # and return standardized names for each column\n",
        "    dau = (trans_df\n",
        "           .groupby(groupby_cols, as_index = False)\n",
        "           .agg({inc_amt : 'sum'})\n",
        "           .rename(columns = {user_id : 'user_id', \n",
        "                              activity_date : 'activity_date', \n",
        "                              inc_amt : 'inc_amt'})\n",
        "                        )\n",
        "\n",
        "    # If we are using a segment column, it gets its own standardized name 'segment'\n",
        "    if segment_col is not None:\n",
        "        dau = dau.rename(columns = {segment_col : 'segment'})\n",
        "        \n",
        "    return dau\n",
        "  \n",
        "# Run the function above and show the first ten rows  \n",
        "dau = create_dau_df(t, \n",
        "                    user_id = 'client_id', \n",
        "                    activity_date = 'date', \n",
        "                    inc_amt = 'value_usd',\n",
        "                    segment_col = 'segment'\n",
        "                   )\n",
        "dau.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>activity_date</th>\n",
              "      <th>segment</th>\n",
              "      <th>inc_amt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>SMB</td>\n",
              "      <td>11.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>SMB</td>\n",
              "      <td>13.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10001A</td>\n",
              "      <td>2015-11-02</td>\n",
              "      <td>SMB</td>\n",
              "      <td>7.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001A</td>\n",
              "      <td>2015-11-22</td>\n",
              "      <td>SMB</td>\n",
              "      <td>18.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10001A</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>SMB</td>\n",
              "      <td>6.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10001A</td>\n",
              "      <td>2017-12-08</td>\n",
              "      <td>SMB</td>\n",
              "      <td>8.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10002A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>Enterprise</td>\n",
              "      <td>11.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10002A</td>\n",
              "      <td>2015-10-26</td>\n",
              "      <td>Enterprise</td>\n",
              "      <td>12.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10002A</td>\n",
              "      <td>2015-11-16</td>\n",
              "      <td>Enterprise</td>\n",
              "      <td>12.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10002A</td>\n",
              "      <td>2015-11-23</td>\n",
              "      <td>Enterprise</td>\n",
              "      <td>12.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  user_id activity_date     segment  inc_amt\n",
              "0  10000A    2015-10-14         SMB    11.75\n",
              "1  10001A    2015-10-14         SMB    13.75\n",
              "2  10001A    2015-11-02         SMB     7.50\n",
              "3  10001A    2015-11-22         SMB    18.00\n",
              "4  10001A    2017-04-04         SMB     6.25\n",
              "5  10001A    2017-12-08         SMB     8.75\n",
              "6  10002A    2015-10-14  Enterprise    11.75\n",
              "7  10002A    2015-10-26  Enterprise    12.25\n",
              "8  10002A    2015-11-16  Enterprise    12.25\n",
              "9  10002A    2015-11-23  Enterprise    12.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "CGXjLYIjxgo5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Create a separate dataframe to hold each user's first activity date\n",
        "Calculate the **first ever activity date** for each user_id in the DAU dataframe, and store it in its own dataframe (**first_dt**). This step is optional because it can be executed within the **create_dau_decorated_df** function below, but we are including it here to illustrate better the mechanics of what is happening."
      ]
    },
    {
      "metadata": {
        "id": "0Rtr2KqNx5Kh",
        "colab_type": "code",
        "outputId": "262743e2-ebd3-4ebd-d1b7-78ca9fa31167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "# The create_first_dt_df function takes as its input the DAU dataframe created\n",
        "# above. After creating a copy of the original DAU dataframe so as not to \n",
        "# affect the original, it creates a new first_dt dataframe. Using the groupby\n",
        "# and agg functions, it finds the minimum Activity Date for each User ID. Then \n",
        "# it specifies the week ('first_week') and month ('first_month') in which the \n",
        "# first Activity Date is found. \n",
        "\n",
        "def create_first_dt_df(dau_df):\n",
        "    print('Creating first_dt dataframe')\n",
        "    \n",
        "    # Create copy of input dataframe\n",
        "    dau = dau_df.copy()\n",
        "    \n",
        "    # Use groupby to find the minimum activity_date for each user_id\n",
        "    first_dt = (dau.groupby(['user_id'], as_index = False)\n",
        "                .agg({'activity_date' : 'min'})\n",
        "                .rename(columns = { 'activity_date' : 'first_dt' })\n",
        "               )\n",
        "    \n",
        "    # Ensure that the first_dt field is a date\n",
        "    first_dt['first_dt'] = pd.to_datetime(first_dt['first_dt']).dt.date\n",
        "    \n",
        "    # Add two new columns with the first_week and first_month of the first_dt\n",
        "    first_dt['first_week'] = pd.to_datetime(first_dt['first_dt']).dt.to_period('W')\n",
        "    first_dt['first_month'] = pd.to_datetime(first_dt['first_dt']).dt.to_period('M')\n",
        "    \n",
        "    return first_dt\n",
        "  \n",
        "  \n",
        "# Run the function above and show the first ten rows  \n",
        "first_dt = create_first_dt_df(dau)\n",
        "first_dt.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating first_dt dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>first_dt</th>\n",
              "      <th>first_week</th>\n",
              "      <th>first_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003A</td>\n",
              "      <td>2015-10-16</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004A</td>\n",
              "      <td>2015-10-15</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10005A</td>\n",
              "      <td>2015-10-25</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10011A</td>\n",
              "      <td>2015-10-16</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10012A</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10013A</td>\n",
              "      <td>2015-10-15</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10014A</td>\n",
              "      <td>2015-10-28</td>\n",
              "      <td>2015-10-26/2015-11-01</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  user_id    first_dt            first_week first_month\n",
              "0  10000A  2015-10-14 2015-10-12/2015-10-18     2015-10\n",
              "1  10001A  2015-10-14 2015-10-12/2015-10-18     2015-10\n",
              "2  10002A  2015-10-14 2015-10-12/2015-10-18     2015-10\n",
              "3  10003A  2015-10-16 2015-10-12/2015-10-18     2015-10\n",
              "4  10004A  2015-10-15 2015-10-12/2015-10-18     2015-10\n",
              "5  10005A  2015-10-25 2015-10-19/2015-10-25     2015-10\n",
              "6  10011A  2015-10-16 2015-10-12/2015-10-18     2015-10\n",
              "7  10012A  2015-10-19 2015-10-19/2015-10-25     2015-10\n",
              "8  10013A  2015-10-15 2015-10-12/2015-10-18     2015-10\n",
              "9  10014A  2015-10-28 2015-10-26/2015-11-01     2015-10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "sl1ofjoCzdgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3 Join DAU with First Date\n",
        "Merge the **dau** dataframe with the **first_dt** dataframe and call it \"**DAU Decorated**.\""
      ]
    },
    {
      "metadata": {
        "id": "RRRg0W1V0BgI",
        "colab_type": "code",
        "outputId": "2ede13f6-4846-49e9-ebe2-216a2ef2d304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "# The create_dau_decorated_df takes the two data frames created above, DAU and\n",
        "# first_dt, and merges them together based on user_id. This results in a DAU\n",
        "# dataframe \"decorated\" with information about the user's first activity date,\n",
        "# first week, and first month, as shown below. Note: it is not necessary to \n",
        "# pass in the first_dt dataframe. If none is provided, the function will run\n",
        "# create_first_dt_df so it has something to merge to the DAU dataframe.\n",
        "\n",
        "def create_dau_decorated_df(dau_df, first_dt_df = None):\n",
        "    print('Creating DAU Decorated dataframe')\n",
        "    \n",
        "    # If no first_dt_df is provided, create it\n",
        "    if first_dt_df is None:\n",
        "        first_dt_df = create_first_dt_df(dau_df)\n",
        "        \n",
        "    # Do a left merge of first_dt_df into dau_df on User ID\n",
        "    dau_decorated_df = dau_df.merge(first_dt_df, how = 'left', on = 'user_id')\n",
        "\n",
        "    # If segment is included in this dataframe, ensure that it is a string type\n",
        "    if 'segment' in dau_decorated_df.columns:\n",
        "        dau_decorated_df['segment'] = dau_decorated_df['segment'].astype('str')\n",
        "    \n",
        "    return dau_decorated_df\n",
        "  \n",
        "  \n",
        "# Run the function above and show the first ten rows  \n",
        "dau_decorated = create_dau_decorated_df(dau, first_dt_df = first_dt)\n",
        "dau_decorated.tail(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating DAU Decorated dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>activity_date</th>\n",
              "      <th>segment</th>\n",
              "      <th>inc_amt</th>\n",
              "      <th>first_dt</th>\n",
              "      <th>first_week</th>\n",
              "      <th>first_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>407208</th>\n",
              "      <td>9995A</td>\n",
              "      <td>2019-01-24</td>\n",
              "      <td>SMB</td>\n",
              "      <td>21.28</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407209</th>\n",
              "      <td>9995A</td>\n",
              "      <td>2019-01-31</td>\n",
              "      <td>SMB</td>\n",
              "      <td>21.28</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407210</th>\n",
              "      <td>9995A</td>\n",
              "      <td>2019-02-07</td>\n",
              "      <td>SMB</td>\n",
              "      <td>21.28</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407211</th>\n",
              "      <td>9995A</td>\n",
              "      <td>2019-02-14</td>\n",
              "      <td>SMB</td>\n",
              "      <td>21.28</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407212</th>\n",
              "      <td>9995A</td>\n",
              "      <td>2019-02-21</td>\n",
              "      <td>SMB</td>\n",
              "      <td>21.28</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407213</th>\n",
              "      <td>9995A</td>\n",
              "      <td>2019-02-28</td>\n",
              "      <td>SMB</td>\n",
              "      <td>21.28</td>\n",
              "      <td>2015-10-19</td>\n",
              "      <td>2015-10-19/2015-10-25</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407214</th>\n",
              "      <td>9998A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>SMB</td>\n",
              "      <td>15.00</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407215</th>\n",
              "      <td>9998A</td>\n",
              "      <td>2015-11-29</td>\n",
              "      <td>SMB</td>\n",
              "      <td>15.00</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407216</th>\n",
              "      <td>9998A</td>\n",
              "      <td>2015-12-30</td>\n",
              "      <td>SMB</td>\n",
              "      <td>7.50</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407217</th>\n",
              "      <td>9999A</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>Enterprise</td>\n",
              "      <td>11.75</td>\n",
              "      <td>2015-10-14</td>\n",
              "      <td>2015-10-12/2015-10-18</td>\n",
              "      <td>2015-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_id activity_date     segment  inc_amt    first_dt  \\\n",
              "407208   9995A    2019-01-24         SMB    21.28  2015-10-19   \n",
              "407209   9995A    2019-01-31         SMB    21.28  2015-10-19   \n",
              "407210   9995A    2019-02-07         SMB    21.28  2015-10-19   \n",
              "407211   9995A    2019-02-14         SMB    21.28  2015-10-19   \n",
              "407212   9995A    2019-02-21         SMB    21.28  2015-10-19   \n",
              "407213   9995A    2019-02-28         SMB    21.28  2015-10-19   \n",
              "407214   9998A    2015-10-14         SMB    15.00  2015-10-14   \n",
              "407215   9998A    2015-11-29         SMB    15.00  2015-10-14   \n",
              "407216   9998A    2015-12-30         SMB     7.50  2015-10-14   \n",
              "407217   9999A    2015-10-14  Enterprise    11.75  2015-10-14   \n",
              "\n",
              "                  first_week first_month  \n",
              "407208 2015-10-19/2015-10-25     2015-10  \n",
              "407209 2015-10-19/2015-10-25     2015-10  \n",
              "407210 2015-10-19/2015-10-25     2015-10  \n",
              "407211 2015-10-19/2015-10-25     2015-10  \n",
              "407212 2015-10-19/2015-10-25     2015-10  \n",
              "407213 2015-10-19/2015-10-25     2015-10  \n",
              "407214 2015-10-12/2015-10-18     2015-10  \n",
              "407215 2015-10-12/2015-10-18     2015-10  \n",
              "407216 2015-10-12/2015-10-18     2015-10  \n",
              "407217 2015-10-12/2015-10-18     2015-10  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "JyYfAz4RxU6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Combining the basic DAU data with the first date, week, and month for each user, **the DAU Decorated dataframe is our basic building block for many different analyses**. It allows us to use user-level data to inspect engagement, retention, and growth accounting.\n",
        "\n",
        "### 2.4 Use DAU Decorated in Subsequent Data Tranformations\n",
        "To see how DAU Decorated is used downstream, please visit the Mini-Pipeline notebooks about the subjects below:\n",
        "\n",
        "\n",
        "*   [MAU Growth Accounting](https://colab.research.google.com/drive/1moHa4Mcycwsz7Fq6T_5Zou1Zunt0afiI)\n",
        "*   [Cohort Analysis](https://colab.research.google.com/drive/1oYy-wJl6VZFgOsv8uw7iGChQxUjrR5rf)\n",
        "*   [Engagement](https://colab.research.google.com/drive/1nznm8WRU0dJcMNAR4U5CpkHpbMI-nmWD)\n"
      ]
    }
  ]
}